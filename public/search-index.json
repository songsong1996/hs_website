[{"content":"Introduction I am blessed to have a cat baby, and I enjoy baking a lot, however recently I started to lose weight. So my amazon records looks like this:\nMonths 1–6: lots of cat stuff (litter mat, fountain, scratching post, treats, toys, carrier). Months 7–9: baking accessories (sheet pans, silicone mats, piping bags, cake turntable, mixer bowl). Last 2 weeks: workout kick (Theragun → whey protein → lifting gloves). Apparently my purchases have sequential dependencies, which are unable to be captured by conventional recommendation systems, including collaborative filtering and content-based filtering, as they model/depict consumers by their interaction to the items and it\u0026rsquo;s order-agnostic and it\u0026rsquo;s also just pair-wise correlation between the consumer and items based on engagements (clicks, conversions etc).\nAnd to model such sequential dependencies, there are a lot of different models from non-DNN, DNN, to latest LLM. This blog post summarizes how each model works for my user behaviors. For difficulties/challenges/characteristics of sequential recommender, please refer to Sequential Recommender Systems: Challenges, Progress and Prospects\nTraditional method Collaborative Filtering - Matrix-factorization CF Matrix-Factorization CF learns a latent vector $p_u$ for each user. Although it\u0026rsquo;s not frequency by category, but in practice, $p_u$ ends up to be: $$p_u \\approx (Q^⊤C_uQ+λI)^{−1} Q^⊤C_ur_u​$$\nHere:\n$|I|$ is the size of items; $k$ is item factor dimensions. $Q \\in \\mathbb{R}^{|I|\\times k}$: Item factor matrix. Row $i$ is the $k$-dim vector for item $i$. $C_u \\in \\mathbb{R}^{|I|\\times |I|}$: A diagonal confidence matrix (all non-diagonal = 0) of user $u$ for items. $c_{ui}$ is the confidence score of user $u$ with item $i$. It\u0026rsquo;s normally derived from engagement data $r_{ui}$ (the interaction #clicks, #conversions): $$c_{ui} = 1 + \\alpha r_{ui}$$ The term $(Q^⊤C_uQ+λI)^{−1}$ is some sort of normalization, while $C_u$ and $r_u$ are both related to consumer engagement, therefore the learned consumer representations end up engagement (clicks/conversions) weighted item vectors. So in my case, my representation will be closest to cat supplies embeddings. Therefore when predict the next items, it will likely end up cat supplies.\nBefore DNN Early Stage Sequence models Sequential pattern mining Mine frequent patterns on sequence data, and then utilize the patterns for subsequent recommendations. Although simple and straightforward, but the patterns could be redundant. e.g. I am buying cat supplies monthly, while sometimes buying bake supplies in between. The pattern could be something like cat_food -\u0026gt; cat_litter -\u0026gt; baking_supplies.\nMarkov Chain Based approaches Basic Markov Chain The hypothesis is future purchase depends only on previous $k$ purchases.\nThis approach assumes that the next item in a sequence depends only on the current state (or the last few states), making it a memoryless process. For example, if I\u0026rsquo;m currently in a \u0026ldquo;baking phase,\u0026rdquo; the model would predict that my next purchase is more likely to be baking-related rather than cat supplies.\nHigher-order Markov Chains Extending the basic Markov assumption to consider more historical context, such as the last 2-3 purchases instead of just the last one.\nDeep Learning Era RNN-based approaches Recurrent Neural Networks can capture longer-term dependencies in sequential data, making them more suitable for modeling complex user behavior patterns.\nAttention-based models Modern attention mechanisms can focus on relevant parts of the purchase history when making recommendations.\nLLM Wave Large Language Models for recommendation Recent advances in LLMs show promise for understanding complex user preferences and generating personalized recommendations based on natural language descriptions of user behavior.\nConclusion Sequential recommendation systems offer a more nuanced understanding of user behavior by considering the temporal order of interactions. While traditional methods focus on static user-item relationships, sequential models can capture evolving preferences and behavioral patterns over time.\n","date":"2025-08-10","id":0,"permalink":"/blog/sequential-recommender-systems-walk-through/","summary":"By modeling the same example, compare the difference of all SRS related methods","tags":["sequential-recommendation","collaborative-filtering","deep-learning"],"title":"Sequential Recommender Systems Walk-Through"},{"content":"","date":"2023-09-07","id":1,"permalink":"/blog/","summary":"","tags":[],"title":"Blog"},{"content":"","date":"2023-09-07","id":2,"permalink":"/docs/guides/","summary":"","tags":[],"title":"Guides"},{"content":"Guides lead a user through a specific task they want to accomplish, often with a sequence of steps. Writing a good guide requires thinking about what your users are trying to do.\nFurther reading Read about how-to guides in the Diátaxis framework ","date":"2023-09-07","id":3,"permalink":"/docs/guides/example-guide/","summary":"\u003cp\u003eGuides lead a user through a specific task they want to accomplish, often with a sequence of steps. Writing a good guide requires thinking about what your users are trying to do.\u003c/p\u003e\n\u003ch2 id=\"further-reading\"\u003eFurther reading\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRead \u003ca href=\"https://diataxis.fr/how-to-guides/\"\u003eabout how-to guides\u003c/a\u003e in the Diátaxis framework\u003c/li\u003e\n\u003c/ul\u003e","tags":[],"title":"Example Guide"},{"content":"","date":"2023-09-07","id":4,"permalink":"/docs/reference/","summary":"","tags":[],"title":"Reference"},{"content":"Reference pages are ideal for outlining how things work in terse and clear terms. Less concerned with telling a story or addressing a specific use case, they should give a comprehensive outline of what your documenting.\nFurther reading Read about reference in the Diátaxis framework ","date":"2023-09-07","id":5,"permalink":"/docs/reference/example-reference/","summary":"\u003cp\u003eReference pages are ideal for outlining how things work in terse and clear terms. Less concerned with telling a story or addressing a specific use case, they should give a comprehensive outline of what your documenting.\u003c/p\u003e\n\u003ch2 id=\"further-reading\"\u003eFurther reading\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRead \u003ca href=\"https://diataxis.fr/reference/\"\u003eabout reference\u003c/a\u003e in the Diátaxis framework\u003c/li\u003e\n\u003c/ul\u003e","tags":[],"title":"Example Reference"},{"content":"Link to valuable, relevant resources.\n","date":"2024-02-27","id":6,"permalink":"/docs/resources/","summary":"\u003cp\u003eLink to valuable, relevant resources.\u003c/p\u003e","tags":[],"title":"Resources"},{"content":"","date":"2023-09-07","id":7,"permalink":"/docs/","summary":"","tags":[],"title":"Docs"},{"content":"","date":"2025-08-10","id":8,"permalink":"/categories/","summary":"","tags":[],"title":"Categories"},{"content":"","date":"2025-08-10","id":9,"permalink":"/tags/collaborative-filtering/","summary":"","tags":[],"title":"Collaborative-Filtering"},{"content":"","date":"2025-08-10","id":10,"permalink":"/tags/deep-learning/","summary":"","tags":[],"title":"Deep-Learning"},{"content":"","date":"2025-08-10","id":11,"permalink":"/categories/machine-learning/","summary":"","tags":[],"title":"Machine-Learning"},{"content":"","date":"2025-08-10","id":12,"permalink":"/categories/recommendation-systems/","summary":"","tags":[],"title":"Recommendation-Systems"},{"content":"","date":"2025-08-10","id":13,"permalink":"/tags/sequential-recommendation/","summary":"","tags":[],"title":"Sequential-Recommendation"},{"content":"","date":"2025-08-10","id":14,"permalink":"/tags/","summary":"","tags":[],"title":"Tags"},{"content":"","date":"2023-09-07","id":15,"permalink":"/privacy/","summary":"","tags":[],"title":"Privacy Policy"},{"content":"","date":"2023-09-07","id":16,"permalink":"/","summary":"","tags":[],"title":"Welcome to Doks"},{"content":"","date":"0001-01-01","id":17,"permalink":"/contributors/","summary":"","tags":[],"title":"Contributors"}]